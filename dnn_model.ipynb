{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>A study on pre-processing video images to improve the accuracy of hand tremor classifiers</center>\n",
    "\n",
    "<center><em>Eduardo Furtado - Master's Dissertation</em></center>\n",
    "<center><em>Advisor: Prof. Dr. Ana Cristina Bicharra Garcia</em></center>\n",
    "<center><em>UNIRIO PPGI - Universidade Federal do Estado do Rio de Janeiro Graduate Program in Computer Science</em></center>\n",
    "\n",
    "In this study, we aim to verify if pre-processing videos of patients performing finger tapping tasks can improve the outcome of pose estimation algorithms, and in turn, enhance the performance of a hand tremor classifier. Finger tapping videos are fundamental in clinical evaluations, aiding in determining the MDS-UPDRS score for Parkinson's patients. As deep neural networks play an increasing role in medical diagnostics, AI stands out as a valuable tool for the early diagnosis of movement disorders. Maintaining high video data quality is essential. Employing 2D videos emerges as a cost-effective and user-friendly strategy that enables remote medical assessments as simple as recording a video with a webcam. By drawing on established methodologies, we hope to provide a robust and clinically relevant approach.\n",
    "\n",
    "Our research unfolds across two objectives, the first one is to reproduce and assess the methodology efficacy of the results presented by **Yang et al.** in `Automatic Detection Pipeline for Accessing the Motor Severity of Parkinson’s Disease in Finger Tapping and Postural Stability`, utilizing the PDMotorDB dataset for hand tremor sevirity classification based on their MDS-UPDRS score. The second objective is to explore the impact of pre-processing techniques to our data can improve the performance of the tremor severity classifier model. In the separate code for data preparation, we draw inspiration from a similar study by **Chen et al.** with their application of the Contrast Limited Adaptive Histogram Equalization (CLAHE) for pose estimation of bedridden patients in clinical conditions, we also perform data augmentation to our dataset by rotating and mirroring each video we have available. Finally, we'll also experiment new features in order to give more information from the extracted finger tapping signal to our classifier model.\n",
    "\n",
    "PDMotorDB dataset: https://github.com/pddata/PDMotorDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline of this study, we will replicate the methodology applied by Yang et al. to create all the domain knowledge features they used and train a DNN model to classify the severity of tremor from the hand videos. Hand landmarks for both the right and left hand and save in a csv file. \n",
    "\n",
    "**From the paper (page 5)**\n",
    "\n",
    "```\n",
    "In the domain knowledge extraction stage, we extract three features: the tapping rate, the tapping frozen times, and the tapping amplitude variation for the finger tapping action. Those features represent the patient’s ability to control their fingers. \n",
    "\n",
    "The tapping rate is defined as the tapping number divided by the time interval. \n",
    "Tapping frozen times is defined as the hesitation number of the patient. \n",
    "The tapping amplitude variation refers to the distance variation in which the patient spread the thumb and the index finger. \n",
    "\n",
    "To calculate the three features above, we first calculate the distance from the thumb to the index finger for each frame. Finger tapping status can be represented by the distances. Those distances compose of a discrete signal, which can form a wave form by connecting the adjacent point. To make the wave form smooth and filter noise, we use low pass filtering to get rid of the frequency with over 4 Hz. Second, we normalize the distance by dividing by the maximum distance to avoid the variation of the hand distance to the camera. For example, when the distance comes to zero, the thumb and the index finger are pressed together. When the distance comes to one, the thumb and the index finger are pulled apart at most. The wave form of one cycle can be viewed as a tapping, shown in Figure 3(a). The mark ‘x’ in yellow represents the local minimal point.\n",
    "\n",
    "From the wave form, the tapping rate can be calculated as the tapping number divided by time. For example, in the first row of Figure 3(b), the tapping rate is the number of ‘x’ mark, the local minimal point divided by five seconds. The tapping rate is 1.6 taps per second in this example. The frozen state is defined as the patient prolonging the current action for a while. In the second row of Figure 3(b), we can see there is an obvious flat line in the center of the wave form. We first calculate the first derivative of the wave form and take the range with small derivatives as the frozen interval. We take the number of the frozen interval as the feature of tapping frozen times. The tapping amplitude refers to the patient’s ability to keep the tapping amplitude. For example, there is an obvious decrease in the amplitude of the wave form, shown in the third row of Figure 3(b). We calculate the standard deviation of the tapping amplitude to grasp the tapping amplitude variation, avoiding the effects of the various absolute pixel distances. Besides, this is also consistent with the criteria in the 3.12 part of MDS-UPDRS.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "method = 'original'      # 'original' / 'clahe' / 'original_augmented'\n",
    "selected_hand = 'L'      # 'L' / 'R'\n",
    "new_features = False     # True / False\n",
    "\n",
    "def load_data(method, selected_hand):\n",
    "    if selected_hand == 'L':\n",
    "        ranges = [(1, 50), (51, 100), (101, 150), (151, 200), (201, 250), (251, 300), (301, 370)]\n",
    "    else:\n",
    "        ranges = [(1, 50), (51, 100), (101, 150), (151, 200), (201, 250)]\n",
    "\n",
    "    if method == 'original':\n",
    "        path = r\"D:\\data\\PDMotorDB\\lr_keypoints_v1\"\n",
    "        df = pd.read_csv(path + fr\"\\data_keypoints_{selected_hand}.csv\")\n",
    "        return df\n",
    "\n",
    "    elif method == 'clahe':\n",
    "        path = r\"D:\\data\\PDMotorDB\\lr_clahe_keypoints_v1\"\n",
    "        df = pd.read_csv(path + fr\"\\data_keypoints_{selected_hand}.csv\")\n",
    "        return df\n",
    "\n",
    "    elif method == 'original_augmented':\n",
    "        path = r\"D:\\data\\PDMotorDB\\lr_keypoints_v1\"\n",
    "        df = pd.read_csv(path + fr\"\\data_keypoints_{selected_hand}.csv\")\n",
    "\n",
    "        path = r\"D:\\data\\PDMotorDB\\lr_augmented_keypoints_v1\"\n",
    "        for lower_than, greater_than in ranges:\n",
    "            df_aux = pd.read_csv(path + fr\"\\data_keypoints_{selected_hand}_{lower_than}_{greater_than}.csv\")\n",
    "            df = pd.concat([df, df_aux])\n",
    "        return df\n",
    "\n",
    "df = load_data(method, selected_hand)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['participant'] = df['Source'].str.replace('.avi', '', regex=False).str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist'] = np.sqrt((df['thumb_tip_x'] - df['index_tip_x'])**2 + \n",
    "                     (df['thumb_tip_y'] - df['index_tip_y'])**2)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the tapping signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "for source in df['Source'].unique():\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df[df['Source']==source]['Frame'], y=df[df['Source']==source]['dist'], mode='markers+lines'))\n",
    "\n",
    "    fig.update_layout(title=f'{source}').show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset of features for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "\n",
    "list_features = ['tapping_rate', 'tapping_std', 'tapping_frozen']\n",
    "new_features_list = ['skewness', 'kurtosis', 'autocorr', 'peak_count', 'signal_entropy', 'wavelet_energy', 'second_derivative']\n",
    "\n",
    "\n",
    "\n",
    "if new_features:\n",
    "    list_features += new_features_list\n",
    "\n",
    "\n",
    "\n",
    "def compute_statistics(dists):\n",
    "    skewness = dists.skew()\n",
    "    kurtosis = dists.kurtosis()\n",
    "    return skewness, kurtosis\n",
    "\n",
    "def compute_autocorrelation(dists):\n",
    "    autocorr = dists.autocorr()\n",
    "    return autocorr\n",
    "\n",
    "\n",
    "def compute_peak_features(dists):\n",
    "    peaks, _ = find_peaks(dists)\n",
    "    peak_count = len(peaks)\n",
    "    return peak_count\n",
    "\n",
    "def compute_entropy(dists):\n",
    "    signal_entropy = entropy(np.histogram(dists)[0])\n",
    "    return signal_entropy\n",
    "\n",
    "\n",
    "def compute_wavelet_features(dists):\n",
    "    coeffs = pywt.wavedec(dists, 'db1', level=2)\n",
    "    cA2, cD2, cD1 = coeffs\n",
    "    wavelet_energy = np.sum(cD2**2) + np.sum(cD1**2)\n",
    "    return wavelet_energy\n",
    "\n",
    "def compute_second_derivative(dists):\n",
    "    second_derivative = np.diff(dists, n=2)\n",
    "    return np.mean(second_derivative**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "video_length_seconds = 5\n",
    "\n",
    "# low pass filter\n",
    "cutoff = 4\n",
    "sampling_rate = 25\n",
    "order = 2\n",
    "normal_cutoff = cutoff / (0.5 * sampling_rate)\n",
    "b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    dataset = []\n",
    "\n",
    "    #for participant in df['participant'].unique(): \n",
    "    for s in df['Source'].unique():             \n",
    "        # print(s)\n",
    "        data = df[(df['Source']==s)].copy()\n",
    "        \n",
    "        data['dist_filter'] = filtfilt(b, a, data['dist'])\n",
    "\n",
    "        data['dist_norm'] = minmax_scale(data['dist_filter'])\n",
    "\n",
    "        # local minima\n",
    "        data['flag_minima_rolling'] = np.where(data['dist_norm'] == data['dist_norm'].rolling(5, center=True).min(), True, False)\n",
    "        \n",
    "        # tapping rate\n",
    "        tapping_rate = data['flag_minima_rolling'].sum() / video_length_seconds\n",
    "\n",
    "        # tapping frozen\n",
    "        data['dist_derivative'] = data['dist_norm'].diff()\n",
    "\n",
    "        frozen_threshold = 0.001\n",
    "\n",
    "        data['frozen_state'] = np.abs(data['dist_derivative']) < frozen_threshold\n",
    "        tapping_frozen = data[data['frozen_state']==True].shape[0]\n",
    "\n",
    "        # tapping standard deviation\n",
    "        tapping_std = data['dist_norm'].std()\n",
    "\n",
    "        if new_features:\n",
    "            # skewness and kurtosis\n",
    "            skewness, kurtosis = compute_statistics(data['dist_norm'])\n",
    "\n",
    "            # autocorrelation\n",
    "            autocorr = compute_autocorrelation(data['dist_norm'])\n",
    "\n",
    "            # peak count\n",
    "            peak_count = compute_peak_features(data['dist_norm'])\n",
    "\n",
    "            # entropy\n",
    "            signal_entropy = compute_entropy(data['dist_norm'])\n",
    "\n",
    "            # wavelet energy\n",
    "            wavelet_energy = compute_wavelet_features(data['dist_norm'])\n",
    "\n",
    "            # second derivative\n",
    "            second_derivative = compute_second_derivative(data['dist_norm'])\n",
    "\n",
    "            dataset.append({'source': s, 'participant': data['participant'].unique()[0], 'tapping_rate': tapping_rate, 'tapping_std': tapping_std, 'tapping_frozen': tapping_frozen, 'skewness': skewness, 'kurtosis': kurtosis, 'autocorr': autocorr, 'peak_count': peak_count, 'signal_entropy': signal_entropy, 'wavelet_energy': wavelet_energy, 'second_derivative': second_derivative})\n",
    "        else:\n",
    "            dataset.append({'source': s, 'participant': data['participant'].unique()[0], 'tapping_rate': tapping_rate, 'tapping_std': tapping_std, 'tapping_frozen': tapping_frozen})\n",
    "\n",
    "    df_dataset = pd.DataFrame.from_records(dataset)\n",
    "    df_dataset.shape\n",
    "\n",
    "    return df_dataset\n",
    "\n",
    "dataset = prepare_dataset(df)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the target values for each video in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.DataFrame()\n",
    "\n",
    "path_target = r\"D:\\data\\PDMotorDB\"\n",
    "\n",
    "files = [path_target + \"\\\\lefthand_train.txt\", path_target + \"\\\\lefthand_val.txt\", \n",
    "         path_target + \"\\\\righthand_train.txt\", path_target + \"\\\\righthand_val.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    participant_prefix = 'L' if 'lefthand' in file else 'R'\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        df_lines = pd.DataFrame(lines, columns=['participant'])\n",
    "        \n",
    "        df_lines['target'] = df_lines['participant'].str.replace('\\n', '').str.split(' ').str[1].astype(int)\n",
    "        df_lines['participant'] = participant_prefix + df_lines['participant'].str.split(' ').str[0]\n",
    "        df_lines['train_val'] = 'train' if 'train' in file else 'val'\n",
    "\n",
    "        #df_target = df_target.append(df_lines)\n",
    "        df_target = pd.concat([df_target, df_lines])\n",
    "df_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.merge(df_target, on='participant', how='left')\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing dirty data from the dataset\n",
    "\n",
    "exclude_ids = [ 'L00008', 'L00013', 'L00031', 'L00035', 'L00036', 'L00042', 'L00075', 'L00095', 'L00098', 'L00104', 'L00105', 'L00116', 'L00139', 'L00170', 'L00188', 'L00189', 'L00191', 'L00193', 'L00198', 'L00214', 'L00217', 'L00228', 'L00231', 'L00233', 'L00236', 'L00244', 'L00251', 'L00253', 'L00255', 'L00258', 'L00262', 'L00263', 'L00271', 'L00282', 'L00284', 'L00294', 'L00305', 'L00307', 'L00312', 'L00338', 'L00343', 'L00368', 'R00017', 'R00034', 'R00035', 'R00041', 'R00054', 'R00060', 'R00063', 'R00071', 'R00074', 'R00085', 'R00088', 'R00105', 'R00118', 'R00138', 'R00139', 'R00146', 'R00159', 'R00178', 'R00194', 'R00195', 'R00197', 'R00203', 'R00212', 'R00214', 'R00243',]\n",
    "\n",
    "dataset = dataset[~dataset['participant'].isin(exclude_ids)]\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data distribution for the features in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "for feature in list_features:\n",
    "    fig = px.histogram(dataset, x=feature, nbins=20, title=feature, marginal=\"box\", hover_data=dataset.columns)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "input_shape = (3 + len(new_features_list),) if new_features else (3,)\n",
    "print(input_shape)\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(1e-6)),\n",
    "        layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(1e-6)),\n",
    "        layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(1e-6)),\n",
    "        layers.Dense(dataset['target'].nunique(), activation='softmax')               \n",
    "    ])\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy',\n",
    "                         tf.keras.metrics.Precision(),\n",
    "                         tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_dataset = dataset[(dataset['train_val']=='train') & (dataset['participant'].str.contains(selected_hand))]\n",
    "\n",
    "test_dataset = dataset[(dataset['train_val']=='val') & (dataset['participant'].str.contains(selected_hand))]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_dataset[list_features], train_dataset['target'], test_size=0.4, random_state=42)\n",
    "\n",
    "print(f'''\n",
    "Train shape: {X_train.shape} {y_train.shape} \\t {np.unique(y_train, return_counts=True)}\n",
    "Val shape:  {X_val.shape} {y_val.shape} \\t {np.unique(y_val, return_counts=True)}\n",
    "''')\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=dataset['target'].nunique())\n",
    "y_val = to_categorical(y_val, num_classes=dataset['target'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "trace_train = go.Scatter(\n",
    "    x=[i for i in range(len(history.history['loss']))],\n",
    "    y=history.history['loss'],\n",
    "    mode='lines', name='Train Loss'\n",
    ")\n",
    "\n",
    "trace_test = go.Scatter(\n",
    "    x=[i for i in range(len(history.history['val_loss']))],\n",
    "    y=history.history['val_loss'],\n",
    "    mode='lines', name='Test Loss'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace_train, trace_test]).update_layout(title=f'Train and Validation Loss over Epochs for <b>{selected_hand} hand</b>', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing 5-fold cross-validation to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Define the number of folds\n",
    "n_splits = 5 \n",
    "\n",
    "# Create StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y = to_categorical(dataset['target'], num_classes=dataset['target'].nunique())\n",
    "\n",
    "# Prepare arrays to store results\n",
    "precision_scores, recall_scores, f1_scores, model_filenames = [], [], [], []\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, val_index in skf.split(dataset[list_features], np.argmax(y, axis=1)):\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val = dataset.iloc[train_index][list_features], dataset.iloc[val_index][list_features]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # Create and compile model\n",
    "    model = create_model()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_scores.append(precision_score(y_true, y_pred_classes, average='macro'))\n",
    "    recall_scores.append(recall_score(y_true, y_pred_classes, average='macro'))\n",
    "    f1_scores.append(f1_score(y_true, y_pred_classes, average='macro'))\n",
    "\n",
    "    output_path = r\"D:\\data\\master_experiments\"\n",
    "    model_filename = f'\\\\model_{selected_hand}_{method}_new_features_{new_features}_{datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")}.h5'\n",
    "    model_filenames.append(model_filename)\n",
    "    # print(model_filename)\n",
    "    model.save(output_path + model_filename)\n",
    "\n",
    "# Calculate average scores across all folds\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Print average scores\n",
    "print(f'''\n",
    "Average Precision: {average_precision}, \n",
    "Average Recall: {average_recall}, \n",
    "Average F1-Score: {average_f1}''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_summary = {\n",
    "    'Hand': selected_hand, \n",
    "    'Experiment': method.title(), \n",
    "    'New Features': new_features,\n",
    "    'Avg Precision': average_precision, \n",
    "    'Avg Recall': average_recall, \n",
    "    'Avg F1': average_f1,\n",
    "    'Precision Scores': precision_scores,\n",
    "    'Recall Scores': recall_scores,\n",
    "    'F1 Scores': f1_scores,\n",
    "    'Models': model_filenames\n",
    "}\n",
    "\n",
    "import json\n",
    "print(json.dumps(experiment_summary, indent=4))\n",
    "\n",
    "with open(output_path + f\"\\\\model_{selected_hand}_{method}_new_features_{new_features}.json\", 'w') as f:\n",
    "    json.dump(experiment_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
